<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Information Theory in LLM Theory | Daniels Blog</title>
<meta name="keywords" content="">
<meta name="description" content="By reading this blogpost, you will find out, why this emoji squence is here: ‚ö†Ô∏è üì• üòö üõ° üö¶ üëπ üåø.
Introduction Background A Brief Introduction on Information Theory In this section we want to provide a brief overview on Information Theory.
Draft:
start with everyday life example, that will make reader think of how one could formalize amount of information
explain shannons information theory
name entropy definition extract definition of information define mutual information, briefly mention why it is usefull briefly name an example applications from coding theory">
<meta name="author" content="">
<link rel="canonical" href="https://strammermax27.github.io/posts/information_theory_in_llm_theory/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="stylesheet" type="text/css" href="/hugo-cite.css" />

<link rel="icon" href="https://strammermax27.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://strammermax27.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://strammermax27.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://strammermax27.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://strammermax27.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://strammermax27.github.io/posts/information_theory_in_llm_theory/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js" integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY" crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

>
<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "$", right: "$", display: false}
        ]
    });
});
</script>


  

<meta property="og:title" content="Information Theory in LLM Theory" />
<meta property="og:description" content="By reading this blogpost, you will find out, why this emoji squence is here: ‚ö†Ô∏è üì• üòö üõ° üö¶ üëπ üåø.
Introduction Background A Brief Introduction on Information Theory In this section we want to provide a brief overview on Information Theory.
Draft:
start with everyday life example, that will make reader think of how one could formalize amount of information
explain shannons information theory
name entropy definition extract definition of information define mutual information, briefly mention why it is usefull briefly name an example applications from coding theory" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://strammermax27.github.io/posts/information_theory_in_llm_theory/" /><meta property="article:section" content="posts" />



<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Information Theory in LLM Theory"/>
<meta name="twitter:description" content="By reading this blogpost, you will find out, why this emoji squence is here: ‚ö†Ô∏è üì• üòö üõ° üö¶ üëπ üåø.
Introduction Background A Brief Introduction on Information Theory In this section we want to provide a brief overview on Information Theory.
Draft:
start with everyday life example, that will make reader think of how one could formalize amount of information
explain shannons information theory
name entropy definition extract definition of information define mutual information, briefly mention why it is usefull briefly name an example applications from coding theory"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://strammermax27.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Information Theory in LLM Theory",
      "item": "https://strammermax27.github.io/posts/information_theory_in_llm_theory/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Information Theory in LLM Theory",
  "name": "Information Theory in LLM Theory",
  "description": "By reading this blogpost, you will find out, why this emoji squence is here: ‚ö†Ô∏è üì• üòö üõ° üö¶ üëπ üåø.\nIntroduction Background A Brief Introduction on Information Theory In this section we want to provide a brief overview on Information Theory.\nDraft:\nstart with everyday life example, that will make reader think of how one could formalize amount of information\nexplain shannons information theory\nname entropy definition extract definition of information define mutual information, briefly mention why it is usefull briefly name an example applications from coding theory",
  "keywords": [
    
  ],
  "articleBody": "By reading this blogpost, you will find out, why this emoji squence is here: ‚ö†Ô∏è üì• üòö üõ° üö¶ üëπ üåø.\nIntroduction Background A Brief Introduction on Information Theory In this section we want to provide a brief overview on Information Theory.\nDraft:\nstart with everyday life example, that will make reader think of how one could formalize amount of information\nexplain shannons information theory\nname entropy definition extract definition of information define mutual information, briefly mention why it is usefull briefly name an example applications from coding theory\nbriefly name an example of neurology where neurons may maximize their entropy\nPhilosofical Interlude: Does Information Exist? Chapter Draft (everything in this draft is very vague, dont read)\nmake reader know that you are critic of your own ideas Previous Section information relied on an assumed probability space what is probability? It is a way to formally express of what can be known and what can not be known? (\u003c- express waeknasses of that thought and derive it and be more precise and present alternatives of expressong of what can be known and what not) Problems of probability: How well can be known what can not be know? Well enough to express probabilitys?\nmaybe also everything can be known and everything happens with probability one (\u003c- drop argument, why one can not be sure that universe is not deterministic universe, by using argument based on an explanation why even anything exists)\nexplain that under that circumstances only physically isolated can be known, using similar ‚Äúproof‚Äù as holding theorems proof include limitations of calculation power into probability? use previous arguments to express where probabilistic assumptions might be off and name examples on how it could affect us practically conclude if we are carefull enough with probabilistic assumptions under scenario a everything has information 0, under scenario b everything has information $\\infty$ and under scenario a using limitation of physical possible calculation power information content is impossibly hard to compute mention that information theory has been usefull anyway The Link of Information Theory and LLMs Analyzing Neural Network Architectures In this chapter results from ( Citation: Jeon, Zhu \u0026 al., 2022 Jeon, H., Zhu, Y. \u0026 Van Roy, B. (2022). An information-theoretic framework for supervised learning. arXiv preprint arXiv:2203.00246. ) and ( Citation: Jeon, Lee \u0026 al., 2024 Jeon, H., Lee, J., Lei, Q. \u0026 Van Roy, B. (2024). An information-theoretic analysis of in-context learning. arXiv preprint arXiv:2401.15530. ) will be discussed. For several generative models models upper bounds have been established of how much information they can generate. These results can be used make statements about the expressiveness of different neuronal architecture. (\u003c- be more precise about expressivemness)\nAn Information Theoretic Perspective Analysis on In-Context Learning In ( Citation: Jeon, Lee \u0026 al., 2024 Jeon, H., Lee, J., Lei, Q. \u0026 Van Roy, B. (2024). An information-theoretic analysis of in-context learning. arXiv preprint arXiv:2401.15530. ) assumptions about the origin of the trianing data of LLMs have been made from which an explanation of in context learning was stated.\nWhat is In-Context Learning Results and Methodology ( Citation: Jeon, Lee \u0026 al., 2024 Jeon, H., Lee, J., Lei, Q. \u0026 Van Roy, B. (2024). An information-theoretic analysis of in-context learning. arXiv preprint arXiv:2401.15530. ) TODO: add theorem numerations of original paper.\nQuick Overview In Analyzing Neural Network Architecture we discussed, how much information a given neural architecture can generate. The infered bounds can also be used to make statements about the training data probability space, if a certain assumption about that training data probability space was made. Which? The training data was generated by a random neural network of a given architecture. We will evaluate the pros and cons of such an assumption in Discusion of their Assumptions. Once the distribution of the distribution (basically the bayesian prior) which generates the data is formalized, we can make formal statements about the optimal (optimal with respect to a chosen loss function) estimator of the distribution of the training data. We call this estimator the optimal Bayesian estimator (OBE). If additionaly one assumes that a well trained transformer acts similarily as well as the oOBE, one can infer from the theoretic performance of the bayesian estimator on the performance on the transformer. When making these assumptions one has to be aware about certain dangers:\nIs the bayesian prior distributio - the assumed distribution of distributions - plausible? Mor on that in Discusion of their Assumptions The estiamtion of the OBE strongly depends on the bayesian prior distribution. If you change this distribution the OBE changes as well. If you assume transformers are really good, such that they are as good as an OBE, then the have to be as good as the OBE that makes correct assumptions on the bayesian prior The Assumed Bayesian Prior Figure 1: The model of ( Citation: Jeon, Lee \u0026 al., 2024 Jeon, H., Lee, J., Lei, Q. \u0026 Van Roy, B. (2024). An information-theoretic analysis of in-context learning. arXiv preprint arXiv:2401.15530. ) of the training data for LLMs. Each square represents a training Document, which has been randomly generated by a sparse mixture of AMs like transformers. Each Pink circle represents a randomly generated AM and for each document a random AM is assigned based on a random random distribution.\nIn this paragraph we will formally state the probabilistic model of ( Citation: Jeon, Lee \u0026 al., 2024 Jeon, H., Lee, J., Lei, Q. \u0026 Van Roy, B. (2024). An information-theoretic analysis of in-context learning. arXiv preprint arXiv:2401.15530. ) for the generation of the training data and in-context window of LLMs.\nWe denote the $M$ as the number of training documents and the training documents with ${D_1,‚Ä¶D_M}$. $D_i$ is the sequence of tokens in the i‚Äôth document. $H_{m,t} := (D_1,‚Ä¶,D_{m-1}, X_1^{(m)},‚Ä¶,X_t^{(m-1)}) $ is an abreviation for the sequence of tokens created by the tokens in the first $m-1$ documents and the first $t$ tokens in the $m$‚Äòth document. $D_{M+1}$ denotes in-context document.\nWe say the distributions of ${D_1,‚Ä¶D_{M+1}}$ can described by autoregressive models (as are transformers) that are parametrized by the random vectors ${\\theta_1,‚Ä¶,\\theta_m }$. We pack for practicality all parameter vectors into one $\\theta := {\\theta_1,‚Ä¶,\\theta_m }$\nThe authors wanted to model $\\theta_1,‚Ä¶,\\theta_m $ such that they have some universal common information, which can be stored in a random variable $\\psi$. This means that the sequence $\\theta_1,‚Ä¶,\\theta_m | \\psi$ shall be iid.\nAdditionally $\\psi$ shall not contain information about any $\\theta_m$ that could not be deducted from enough samples of $\\theta_i$, $D_m \\bot \\psi | \\theta$. Since we sayd $\\theta_1,‚Ä¶,\\theta_m | \\psi$ shall be iid, it holds $D_m \\bot \\psi | \\theta \\iff D_m \\bot \\psi | \\theta_m$. (\u003c- not peer reviewed)\n(\u003c- Check if this is correct) How can the random sequence $\\theta_1,‚Ä¶,\\theta_m$ be modeled to satisfy that constraint in such a way, that the distributions of $\\theta_1,‚Ä¶,\\theta_m$ and $\\psi$ are well enough defined. In ( Citation: Jeon, Lee \u0026 al., 2024 Jeon, H., Lee, J., Lei, Q. \u0026 Van Roy, B. (2024). An information-theoretic analysis of in-context learning. arXiv preprint arXiv:2401.15530. ) the authors came up with the clever solution for satisfying these constraints. They defined a random set of $N$ randomly initialized autoregressive models $T = {\\theta^{(1)},‚Ä¶, \\theta^{(N)} }$, where $N$ is an unknown number. Then they defined a random assignment of Documents and autoregresive models in T parametrized by random random distribution $\\alpha \\sim \\text{Dirichlet}(N, (R/N, ‚Ä¶, R/N))$, with $R¬´N$. $\\alpha$ defines for a random autoregressive model $\\theta^{(n)}$ its probability to be assigned for Documents. The smaller the values in the parameter-tuple $(R/N,‚Ä¶,R/N)$ of the Dirichlet distribution, the more sparse the distribution. Lets suppose for example if you have a factory that produces factories, which in return produce each $k$ dices and you want the dieces to be fair (each side appears with same probability). Then the dirichlet distribution, parametrized by $k, (a,‚Ä¶,a)$, which describes the distribution of the probability distribution dices created by a given dice factory should have a high value of $a$ in its paramatrization. So now we can finally define $\\psi := (\\alpha, \\theta^{(1)}, ‚Ä¶, \\theta^{(n)} )$. Note that $\\theta_m | \\psi$ is a discrete random variable with at most $N$ outcomes, therefore its entropy has an upper bound of $\\log N$. Therefore if $M$ grows to infinity maybe the OBE will learn $\\psi$ from $H_M^T$, e.g. $\\log N \\geq \\mathbb H(\\theta_{M+1} | \\psi) \\approx \\mathbb H(\\theta_{M+1}|H_M^T)$ and this may result in a logaritmic upper bound for the estimation error of $\\theta_{M+1}|H_M^T$. You wonder what the estimation error is? This will be formaly definded in the next Paragraph. On top of that the previous claim will be formally evaluated in the next paragraph.\nYou might remember that earlier in this chapter I said that the authors assumed, that all training data has been generated by a transformer. And now I suddently presented a sparse mixture of transformers instead of a transformer. This is because in the conclusion the authors said, that they hope, how further mathematical analysis will be able di describe how a transformer can implement a sparce mixtrue of transformers. So actually they did not make this assumption, but this assumption might be made in the future once it has been prooven that a transformer can implement a sparce mixtre of transformers.\n(TODO proof that a sparse mixture of transformers with fiven transformers has an infinite horizon)\nResults for in-context learning Results without making assumptions about the bayesian prior In this paragraph we outline the results ( Citation: Jeon, Lee \u0026 al., 2024 Jeon, H., Lee, J., Lei, Q. \u0026 Van Roy, B. (2024). An information-theoretic analysis of in-context learning. arXiv preprint arXiv:2401.15530. ) drew from this models of data generation, by analyzing the optimal bayesian estimator $\\hat P$ for the probability distribution of $X^{(m)}_{t+1}$ given $H_t^{(m)}$.\nThe optimal bayesian estimator is defined to be the estimator for the probability $P$ that minimizes this loss function:\n$\\mathbb L_{M,T}(P) = \\frac{1}{TM} \\sum_{m=1}^{M} \\sum_{t=0}^{T-1} \\mathbb E[ - \\ln P(H_t^{(m)})(X_{t+1}^{(m)})]$\nA little remark on the expression $P(H_t^{(m)})(X_{t+1}^{(m)})$: $P$ is a function that takes in an event like $H_t^{(m)}$, and returns a function, namely an estmated distribution for $X_{t+1}^{(m)}$. Therefore there are two braket pairs after $P$ in the above equation.\nIn ( Citation: Jeon, Lee \u0026 al., 2024 Jeon, H., Lee, J., Lei, Q. \u0026 Van Roy, B. (2024). An information-theoretic analysis of in-context learning. arXiv preprint arXiv:2401.15530. ) it was shown, that $\\hat P(H_t^{(m)}) = (x \\to \\mathbb P[X_{t+1}^{(m)} = x|H_t^{(m)}])$ (If $X$ is not discrete the left equation has to be expressed slightly differently).\nLet‚Äôs denote the loss of the minimal bayesian optimizer with $\\mathbb L_{M,T} := \\mathbb L_{M,T}(\\hat P) = \\frac{1}{TM} \\sum_{m=1}^{M} \\sum_{t=0}^{T-1} \\mathbb E[ - \\ln \\mathbb P[X_{t+1}^{(m)}|H_t^{(m)}]]$.\nAs autoregressive models such as transformers define a probability distribution one can not predict a sequence of tokens they generate with probability 1, even if one knows all of their parameters $\\theta$ (Expect of course if they are deterministic autoregressive models). This means that $\\mathbb H(H_T^{(M)}|\\theta)$, e.g. the hardness of predicting the sequence even if the autoregressive model is known, has a value above 0 and might grow to infinity with T or M. The Authors named this error ‚Äúthe irreducible error‚Äù. As we are interessted in how hard it is to estimate not the series of tokens itself, but their distribution, the error $\\mathcal L_{M,T} = \\mathbb L_{M,T} - \\dfrac{\\mathbb H(H_T^{(M)}|\\theta)}{MT}$ will be more insightfull in our exploration. They call this error ‚Äúestimation error‚Äù.\nIn the rest of this section we will present derived expressions for $\\mathcal L_{M,T}$, that provide insights in how easy or hard it is to estimate model parameters, if the data was generated as discussed. Then we derive from this result an expression of the in-context error $\\mathbb L_\\tau := \\frac{1}{\\tau} \\sum_{t=0}^{\\tau-1} \\mathbb E \\ln \\mathbb P(X_{t+1}^{(M+1)}| H_t^{(M+1)})$, where $\\tau$ is the length of the in-context document.\nFirstly we discuss two information theoretic results of $\\mathcal L_{M,T}$.\n$\\mathcal L_{M,T} = \\dfrac{\\mathbb I(H_T^{(M)};\\theta)}{MT}$\nProof:\nWe know $\\mathbb H(X) = \\mathbb H(X|Y) + \\mathbb I(X;Y)$, therfore it suffices to show that $\\mathbb L_{M,T} \\cdot MT = \\mathbb H(H_T^{(M)})$. This is true since:\n$\\sum_{m=1}^{M} \\sum_{t=0}^{T-1} \\mathbb E[ - \\ln \\mathbb P[X_{t+1}^{(m)}|H_t^{(m)}]] = \\mathbb E[-\\ln \\prod_{m=1}^{M} \\prod_{t=0}^{T-1} \\mathbb P[X_{t+1}^{(m)}|H_t^{(m)}]] \\overset{a)}{=} \\mathbb E[-\\ln \\mathbb P[H_T^{(M)}]]= \\mathbb H(H_T^{(M)})$\na) follows from the chain rule of probability.\nQED\nBe aware I often do mistakes, when proofing something. I presented my own version of the proof of this equation as it contains the intermediate result $\\mathbb L_{M,T} = \\dfrac{\\mathbb H(H_T^{(M)})}{MT}$. Thus we can see $\\mathbb L_{M,T}$ as the average entropy per token.\nThis equation means roughly speaking, that the estimation error consits of these parts in $\\theta$, that are conveyed to $H_T^{(M)}$. For example as we often model $\\theta$ as a continous random variable and $H_T^{(M)}$ as a discrete random variable, $H_T^{(M)}$ can not contain all information in $\\theta$. (\u003c- be more clear)\nAs in previous section, we have worked out a way to separate $\\theta = \\theta_1, ‚Ä¶\\theta_m$ into two independent random variables, namely $\\theta|\\psi$ and $\\psi$, we continue by expressing $\\mathcal L_{M,T}$ with these two random variables.\n$\\mathcal L_{M,T} = \\underbrace{\\dfrac{\\mathbb I(H_T^{(M)};\\psi)}{MT}}\\text{meta estimation error} + \\underbrace{\\dfrac{\\mathbb I(D_m;\\theta_m|\\psi)}{T}}\\text{intra document estimation error}$\nTo proof this equation it suffices to show\nA) $\\mathbb I(H_T^{(M)};\\theta) = \\mathbb I(H_T^{(M)};\\psi) + \\mathbb I(H_T^{(M)};\\theta|\\psi) $ B) $\\mathbb I(H_T^{(M)};\\theta|\\psi) = M \\cdot \\mathbb I(D_m;\\theta_m|\\psi)$ We defined earlier $D_m \\bot \\psi | \\theta_m$, which means $ H_T^{(M)} \\bot \\psi | \\theta$ (\u003c- be more formal?). Therefore $\\mathbb I(H_T^{(M)};\\theta) = \\mathbb I(H_T^{(M)};(\\theta, \\psi))$. Then A) follows from the chain rule of mutual information.\nB) follows from $\\mathbb I(H_T^{(M)};\\theta|\\psi) \\overset{a)}{=} \\sum_{m=1}^M \\mathbb I(D_m;\\theta_m|\\psi) \\overset{b)}{=} M\\cdot \\mathbb I(D_m;\\theta_m|\\psi) $.\nEquation a) holds because the pairs $(D_1, \\theta_1)|\\psi, ‚Ä¶, (D_M, \\theta_M)|\\psi$ are independent and mutual information is additive for independent variables.(http://www.scholarpedia.org/article/Mutual_information)\nAs $ D_1,‚Ä¶,D_M | \\psi$ are identically distributed and $\\theta_1, ‚Ä¶, \\theta_M | \\psi$ are identically distributed, for any $a,b \\in {1,‚Ä¶,M}$, $I(D_a;\\theta_a|\\psi) = I(D_b;\\theta_b|\\psi)$. Therefore b) is true.\n(\u003c- proof not peer reviewed) QED\nThe authors seperate the term into two parts, the meta estimation error and the intra document estimation error. The meta estimation error describes the error, of learning information shared shared by all documents. The intra document estimation error is the error of learning the parameters of learning individual documents after having learned the shared information $\\psi$. Lets say we have arbitrarily many training samples $A$ for our optimal bayesian estimator in which $D_m$ does not occur. Due to them being arbitrarily many, let‚Äôs suppose $\\psi$ has been well enough discovered, such that $\\mathbb I(D_m;\\psi | A)$ is about 0. Then the error of estimating $D_m$ is about the intra-document error. This means, that even of we perfectly train our model, there will be some error bigger than zero related to the estimation of the probability that generates the data? Or will it realy be bigger than zero? More on this cliffhanger later (\u003c- TODO!)\nResults from assumptions of bayesian prior Discusion of their Assumptions When can we make assumptions of the the familie of AMs Lets suppose following scenario: we have a sequence of random tokens $X_1, ‚Ä¶, X_T$ and know that this sequence is autoregressive with finite horizon T-d, which means $\\mathbb P(X_{t+1} | X_{t-T+d}, ‚Ä¶, X_{t-1}) = \\mathbb P(X_{t+1}|H_t, X_{t+2}, ‚Ä¶X_{T})$. Then, the distribution of $H_T$ can be charachterized by the function $f(H_t) = \\mathbb P(X_{t+1} | H_t)$. Thus there is a trivial bijection from the set ${ \\Sigma^{T-d} \\to \\mathcal P_\\Sigma }$ to the Autoregressive distributions over the alphabet $\\Sigma$ and length $T$ and horizon $T-d$. (\u003c- warning you have to integrate the non character sign to sigma and that can only be place to the right position (change $\\Sigma^T$)).\nLets suppose we are reely lucky and find a parmatrization of all autoregressive distributions of horizon T-d by finding an injektive function $A :\\mathbb J_\\sigma^n \\to {\\Sigma^{T-d} \\to \\mathcal P_\\Sigma }$, where $\\mathbb J_\\sigma ^n := {||x||_2 = \\sigma, \\mathbb{1} ^T x=0 | x \\in \\mathbb R^n}$.\n(\nLet now $\\Theta \\sim \\mathcal N(0,I_n\\sigma)$. Then $A(\\Theta)$ is a random random distribution which itself is a random distribution. This means $A(\\Theta) \\in {\\Sigma^T \\to \\mathcal P_\\Sigma }$ (Note $X \\sim \\mathcal N(0,1) \\to x \\notin \\mathbb R$)\nIf A exists, and we insert random vector into A, then that random variable is element of As image\nTo recapulate, we assumed/showed evidence, that there can exist a pair $A_t,\\theta$ that can generate any upper bounded horizon distribution, when $\\theta$ is empirical gaussian and $A_t$ is a parametrization function for transformers. Lets suppose we wanted to use that knowledge to find an upper bound for the error of the optimal bayeisan optimizer e.g. an upper bound of the mutual information H_t Theta. Can we do that by using the random random distribution $\\Theta \\sim \\mathcal N(0,\\sigma)$, as that way $\\Theta$ is the probability distribution with maximal differential entropy?\nThe problem is, that there exists $\\theta \\in \\mathbb J^n$, s.t. $A(\\theta) = A(\\Theta)$.\nThe problem is, that this assumes, that $A$ is the only function (it is actually class of function) that can do that (explain what). Why suppose B (b entagles and makes dependencies)\n) !!!!!! But $A(\\theta)$ only has horizon of $K",
  "wordCount" : "3105",
  "inLanguage": "en",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://strammermax27.github.io/posts/information_theory_in_llm_theory/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Daniels Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://strammermax27.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://strammermax27.github.io/" accesskey="h" title="Daniels Blog (Alt + H)">Daniels Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Information Theory in LLM Theory
    </h1>
    <div class="post-meta">

</div>
  </header> 
  <div class="post-content"><p><em>By reading this blogpost, you will find out, why this emoji squence is here:</em> ‚ö†Ô∏è üì• üòö üõ° üö¶ üëπ üåø.</p>
<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<h2 id="background">Background<a hidden class="anchor" aria-hidden="true" href="#background">#</a></h2>
<h3 id="a-brief-introduction-on-information-theory">A Brief Introduction on Information Theory<a hidden class="anchor" aria-hidden="true" href="#a-brief-introduction-on-information-theory">#</a></h3>
<p>In this section we want to provide a brief overview on Information Theory.</p>
<p>Draft:</p>
<ul>
<li>
<p>start with everyday life example, that will make reader think of how one could formalize amount of information</p>
</li>
<li>
<p>explain shannons information theory</p>
<ul>
<li>name entropy definition</li>
<li>extract definition of information</li>
<li>define mutual information, briefly mention why it is usefull</li>
</ul>
</li>
<li>
<p>briefly name an example applications from coding theory</p>
</li>
<li>
<p>briefly name an example of neurology where neurons may maximize their entropy</p>
</li>
</ul>
<h3 id="philosofical-interlude-does-information-exist">Philosofical Interlude: Does Information Exist?<a hidden class="anchor" aria-hidden="true" href="#philosofical-interlude-does-information-exist">#</a></h3>
<p>Chapter Draft (everything in this draft is very vague, dont read)</p>
<ul>
<li>make reader know that you are critic of your own ideas</li>
<li>Previous Section information relied on an assumed probability space</li>
<li>what is probability? It is a way to formally express of what can be known and what can not be known? (&lt;- express waeknasses of that thought and derive it and be more precise and present alternatives of expressong of what can be known and what not)</li>
<li>Problems of probability:
<ul>
<li>
<p>How well can be known what can not be know? Well enough to express probabilitys?</p>
</li>
<li>
<p>maybe also everything can be known and everything happens with probability one (&lt;- drop argument, why one can not be sure that universe is not deterministic universe, by using argument based on an explanation why even anything exists)</p>
<ul>
<li>explain that under that circumstances only physically isolated can be known, using similar &ldquo;proof&rdquo; as holding theorems proof</li>
<li>include limitations of calculation power into probability?</li>
</ul>
</li>
</ul>
</li>
<li>use previous arguments to express where probabilistic assumptions might  be off and name examples on how it could affect us practically</li>
<li>conclude if we are carefull enough with probabilistic assumptions under scenario a everything has information 0, under scenario b everything has information $\infty$ and under scenario a using limitation of physical possible calculation power information content is impossibly hard to compute</li>
<li>mention that information theory has been usefull anyway</li>
</ul>
<h2 id="the-link-of-information-theory-and-llms">The Link of Information Theory and LLMs<a hidden class="anchor" aria-hidden="true" href="#the-link-of-information-theory-and-llms">#</a></h2>
<h2 id="anal_nn">Analyzing Neural Network Architectures<a hidden class="anchor" aria-hidden="true" href="#anal_nn">#</a></h2>
<p><img loading="lazy" src="/figures/assumption_for_ideal_bayesian_estimator.png" alt="targets"  title="Assumption AM"  />
</p>
<p>In this chapter results from 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#jeon2022information"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hong Jun"><span itemprop="familyName">Jeon</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Yifan"><span itemprop="familyName">Zhu</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2022</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jeon</span>,&#32;
    <meta itemprop="givenName" content="Hong Jun" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhu</span>,&#32;
    <meta itemprop="givenName" content="Yifan" />
    Y.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Roy</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">An information-theoretic framework for supervised learning</span>.<i>
    <span itemprop="about">arXiv preprint arXiv:2203.00246</span></i>.</span>




</span></span>)</span>
 and 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#jeon2024information"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hong Jun"><span itemprop="familyName">Jeon</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jason D"><span itemprop="familyName">Lee</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2024</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jeon</span>,&#32;
    <meta itemprop="givenName" content="Hong Jun" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lee</span>,&#32;
    <meta itemprop="givenName" content="Jason D" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lei</span>,&#32;
    <meta itemprop="givenName" content="Qi" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Roy</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2024</span>).
  &#32;<span itemprop="name">An information-theoretic analysis of in-context learning</span>.<i>
    <span itemprop="about">arXiv preprint arXiv:2401.15530</span></i>.</span>




</span></span>)</span>
 will be discussed. For several generative models models upper bounds have been established of how much information they can generate. These results can be used make statements about the expressiveness of different neuronal architecture. (&lt;- be more precise about expressivemness)</p>
<h2 id="an-information-theoretic-perspective-analysis-on-in-context-learning">An Information Theoretic Perspective Analysis on In-Context Learning<a hidden class="anchor" aria-hidden="true" href="#an-information-theoretic-perspective-analysis-on-in-context-learning">#</a></h2>
<p>In 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#jeon2024information"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hong Jun"><span itemprop="familyName">Jeon</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jason D"><span itemprop="familyName">Lee</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2024</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jeon</span>,&#32;
    <meta itemprop="givenName" content="Hong Jun" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lee</span>,&#32;
    <meta itemprop="givenName" content="Jason D" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lei</span>,&#32;
    <meta itemprop="givenName" content="Qi" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Roy</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2024</span>).
  &#32;<span itemprop="name">An information-theoretic analysis of in-context learning</span>.<i>
    <span itemprop="about">arXiv preprint arXiv:2401.15530</span></i>.</span>




</span></span>)</span>
 assumptions about the origin of the trianing data of LLMs have been made from which an explanation of in context learning was stated.</p>
<h3 id="what-is-in-context-learning">What is In-Context Learning<a hidden class="anchor" aria-hidden="true" href="#what-is-in-context-learning">#</a></h3>
<h3 id="results-and-methodology-hahahugoshortcode2s3hbhb">Results and Methodology 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#jeon2024information"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hong Jun"><span itemprop="familyName">Jeon</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jason D"><span itemprop="familyName">Lee</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2024</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jeon</span>,&#32;
    <meta itemprop="givenName" content="Hong Jun" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lee</span>,&#32;
    <meta itemprop="givenName" content="Jason D" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lei</span>,&#32;
    <meta itemprop="givenName" content="Qi" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Roy</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2024</span>).
  &#32;<span itemprop="name">An information-theoretic analysis of in-context learning</span>.<i>
    <span itemprop="about">arXiv preprint arXiv:2401.15530</span></i>.</span>




</span></span>)</span>
</h3>
<p>TODO: add theorem numerations of original paper.</p>
<h4 id="quick-overview">Quick Overview<a hidden class="anchor" aria-hidden="true" href="#quick-overview">#</a></h4>
<!-- raw HTML omitted -->
<p>In <a href="#anal_nn">Analyzing Neural Network Architecture</a> we discussed, how much information a given neural architecture can generate. The infered bounds can also be used to make statements about the training data probability space, if a certain assumption about that training data probability space was made. Which? The training data was generated by a random neural network of a given architecture. We will evaluate the pros and cons of such an assumption in <a href="#discussion-assumptions">Discusion of their Assumptions</a>. Once the distribution of the distribution (basically the bayesian prior) which generates the data  is formalized, we can make formal statements about the optimal (optimal with respect to a chosen loss function) estimator of the distribution of the training data. We call this estimator the optimal Bayesian estimator (OBE). If additionaly one assumes that a well trained transformer acts similarily as well as the oOBE, one can infer from the theoretic performance of the bayesian estimator on the performance on the transformer. When making these assumptions one has to be aware about certain dangers:</p>
<ul>
<li>Is the bayesian prior distributio - the assumed distribution of distributions - plausible? Mor on that in <a href="#discussion-assumptions">Discusion of their Assumptions</a></li>
<li>The estiamtion of the OBE strongly depends on the bayesian prior distribution. If you change this distribution the OBE changes as well. If you assume transformers are really good, such that they are as good as an OBE, then the have to be as good as the OBE that makes correct assumptions on the bayesian prior</li>
</ul>
<h4 id="the-assumed-bayesian-prior">The Assumed Bayesian Prior<a hidden class="anchor" aria-hidden="true" href="#the-assumed-bayesian-prior">#</a></h4>
<p><img loading="lazy" src="/figures/assumption_sparse_mixture.png" alt="targets"  title="Assumptio Sparse Mixture"  />
</p>
<p>Figure 1: The model of 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#jeon2024information"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hong Jun"><span itemprop="familyName">Jeon</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jason D"><span itemprop="familyName">Lee</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2024</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jeon</span>,&#32;
    <meta itemprop="givenName" content="Hong Jun" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lee</span>,&#32;
    <meta itemprop="givenName" content="Jason D" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lei</span>,&#32;
    <meta itemprop="givenName" content="Qi" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Roy</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2024</span>).
  &#32;<span itemprop="name">An information-theoretic analysis of in-context learning</span>.<i>
    <span itemprop="about">arXiv preprint arXiv:2401.15530</span></i>.</span>




</span></span>)</span>
 of the training data for LLMs. Each square represents a training Document, which has been randomly generated by a sparse mixture of AMs like transformers. Each Pink circle represents a randomly generated AM and for each document a random AM is assigned based on a random random distribution.</p>
<p>In this paragraph we will formally state the probabilistic model of 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#jeon2024information"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hong Jun"><span itemprop="familyName">Jeon</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jason D"><span itemprop="familyName">Lee</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2024</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jeon</span>,&#32;
    <meta itemprop="givenName" content="Hong Jun" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lee</span>,&#32;
    <meta itemprop="givenName" content="Jason D" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lei</span>,&#32;
    <meta itemprop="givenName" content="Qi" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Roy</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2024</span>).
  &#32;<span itemprop="name">An information-theoretic analysis of in-context learning</span>.<i>
    <span itemprop="about">arXiv preprint arXiv:2401.15530</span></i>.</span>




</span></span>)</span>
 for the generation of the training data and in-context window of LLMs.</p>
<p>We denote the $M$ as the number of training documents and the training documents with ${D_1,&hellip;D_M}$. $D_i$ is the sequence of tokens in the i&rsquo;th document. $H_{m,t} := (D_1,&hellip;,D_{m-1}, X_1^{(m)},&hellip;,X_t^{(m-1)}) $ is an abreviation for the sequence of tokens created by the tokens in the first $m-1$ documents and the first $t$ tokens in the $m$&lsquo;th document. $D_{M+1}$ denotes in-context document.</p>
<p>We say the distributions of ${D_1,&hellip;D_{M+1}}$ can described by autoregressive models (as are transformers) that are parametrized by the random vectors ${\theta_1,&hellip;,\theta_m }$. We pack for practicality all parameter vectors into one $\theta := {\theta_1,&hellip;,\theta_m }$</p>
<p>The authors wanted to model $\theta_1,&hellip;,\theta_m $ such that they have some universal common information, which can be stored in a random variable $\psi$. This means that the sequence $\theta_1,&hellip;,\theta_m | \psi$ shall be iid.</p>
<p>Additionally $\psi$ shall not contain information about any $\theta_m$ that could not be deducted from enough samples of $\theta_i$,   $D_m \bot \psi | \theta$. Since we sayd $\theta_1,&hellip;,\theta_m | \psi$ shall be iid, it holds  $D_m \bot \psi | \theta \iff D_m \bot \psi | \theta_m$. (&lt;- not peer reviewed)</p>
<p>(&lt;- Check if this is correct)
How can the random sequence $\theta_1,&hellip;,\theta_m$ be modeled to satisfy that constraint in such a way, that the distributions of $\theta_1,&hellip;,\theta_m$ and $\psi$ are well enough defined. In 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#jeon2024information"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hong Jun"><span itemprop="familyName">Jeon</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jason D"><span itemprop="familyName">Lee</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2024</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jeon</span>,&#32;
    <meta itemprop="givenName" content="Hong Jun" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lee</span>,&#32;
    <meta itemprop="givenName" content="Jason D" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lei</span>,&#32;
    <meta itemprop="givenName" content="Qi" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Roy</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2024</span>).
  &#32;<span itemprop="name">An information-theoretic analysis of in-context learning</span>.<i>
    <span itemprop="about">arXiv preprint arXiv:2401.15530</span></i>.</span>




</span></span>)</span>
 the authors came up with the clever solution for satisfying these constraints. They defined a random set of $N$ randomly initialized autoregressive models $T = {\theta^{(1)},&hellip;, \theta^{(N)} }$, where $N$ is an unknown number. Then they defined a random assignment of Documents and autoregresive models in T parametrized by random random distribution $\alpha \sim \text{Dirichlet}(N, (R/N, &hellip;, R/N))$, with $R&laquo;N$. $\alpha$ defines for a random autoregressive model $\theta^{(n)}$ its probability to be assigned for Documents. The smaller the values in the parameter-tuple $(R/N,&hellip;,R/N)$ of the Dirichlet distribution, the more sparse the distribution. Lets suppose for example if you have a factory that produces factories, which in return produce each $k$ dices and you want the dieces to be fair (each side appears with same probability). Then the dirichlet distribution, parametrized by $k, (a,&hellip;,a)$, which describes the distribution of the probability distribution dices created by a given dice factory should have a high value of $a$ in its paramatrization. <!-- raw HTML omitted -->
So now we can finally define $\psi := (\alpha, \theta^{(1)}, &hellip;, \theta^{(n)} )$. Note that $\theta_m | \psi$ is a discrete random variable with at most $N$ outcomes, therefore its entropy has an upper bound of $\log N$.
Therefore if $M$ grows to infinity maybe the OBE will learn $\psi$ from $H_M^T$, e.g. $\log N \geq \mathbb H(\theta_{M+1} | \psi) \approx \mathbb H(\theta_{M+1}|H_M^T)$ and this may result in a logaritmic upper bound for the estimation error of $\theta_{M+1}|H_M^T$. You wonder what the estimation error is? This will be formaly definded in the next Paragraph. On top of that the previous claim will be formally evaluated in the next paragraph.</p>
<p>You might remember that earlier in this chapter I said that the authors assumed, that all training data has been generated by a transformer. And now I suddently presented a sparse mixture of transformers instead of a transformer. This is because in the conclusion the authors said, that they hope, how further mathematical analysis will be able di describe how a transformer can implement a sparce mixtrue of transformers. So actually they did not make this assumption, but this assumption might be made in the future once it has been prooven that a transformer can implement a sparce mixtre of transformers.</p>
<p>(TODO proof that a sparse mixture of transformers with fiven transformers has an infinite horizon)</p>
<h4 id="results-for-in-context-learning">Results for in-context learning<a hidden class="anchor" aria-hidden="true" href="#results-for-in-context-learning">#</a></h4>
<h5 id="results-without-making-assumptions-about-the-bayesian-prior">Results without making assumptions about the bayesian prior<a hidden class="anchor" aria-hidden="true" href="#results-without-making-assumptions-about-the-bayesian-prior">#</a></h5>
<p>In this paragraph we outline the results 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#jeon2024information"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hong Jun"><span itemprop="familyName">Jeon</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jason D"><span itemprop="familyName">Lee</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2024</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jeon</span>,&#32;
    <meta itemprop="givenName" content="Hong Jun" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lee</span>,&#32;
    <meta itemprop="givenName" content="Jason D" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lei</span>,&#32;
    <meta itemprop="givenName" content="Qi" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Roy</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2024</span>).
  &#32;<span itemprop="name">An information-theoretic analysis of in-context learning</span>.<i>
    <span itemprop="about">arXiv preprint arXiv:2401.15530</span></i>.</span>




</span></span>)</span>
 drew from this models of data generation, by analyzing the optimal bayesian estimator $\hat P$ for the probability distribution of $X^{(m)}_{t+1}$ given $H_t^{(m)}$.</p>
<p>The optimal bayesian estimator is  defined to be  the estimator for the probability $P$ that minimizes this loss function:</p>
<p>$\mathbb L_{M,T}(P) = \frac{1}{TM} \sum_{m=1}^{M} \sum_{t=0}^{T-1} \mathbb E[ - \ln P(H_t^{(m)})(X_{t+1}^{(m)})]$</p>
<p>A little remark on the expression $P(H_t^{(m)})(X_{t+1}^{(m)})$: $P$ is a function that takes in an event like $H_t^{(m)}$, and returns a function, namely an estmated distribution for $X_{t+1}^{(m)}$. Therefore there are two braket pairs after $P$ in the above equation.</p>
<p>In 




<span class="hugo-cite-intext"
        itemprop="citation">(<span class="hugo-cite-group">

          <a href="#jeon2024information"><span class="visually-hidden">Citation: </span><span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Hong Jun"><span itemprop="familyName">Jeon</span></span>,&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="givenName" content="Jason D"><span itemprop="familyName">Lee</span></span>
                  <em>&amp; al.</em>,&#32;<span itemprop="datePublished">2024</span></a><span class="hugo-cite-citation"> 










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jeon</span>,&#32;
    <meta itemprop="givenName" content="Hong Jun" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lee</span>,&#32;
    <meta itemprop="givenName" content="Jason D" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lei</span>,&#32;
    <meta itemprop="givenName" content="Qi" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Roy</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2024</span>).
  &#32;<span itemprop="name">An information-theoretic analysis of in-context learning</span>.<i>
    <span itemprop="about">arXiv preprint arXiv:2401.15530</span></i>.</span>




</span></span>)</span>
 it was shown, that $\hat P(H_t^{(m)}) = (x \to \mathbb P[X_{t+1}^{(m)} = x|H_t^{(m)}])$ (If $X$ is not discrete the left equation has to be expressed slightly differently).</p>
<p>Let&rsquo;s denote the loss of the minimal bayesian optimizer with $\mathbb L_{M,T} := \mathbb L_{M,T}(\hat P) = \frac{1}{TM} \sum_{m=1}^{M} \sum_{t=0}^{T-1} \mathbb E[ - \ln \mathbb P[X_{t+1}^{(m)}|H_t^{(m)}]]$.</p>
<p>As autoregressive models such as transformers define a probability distribution one can not predict a sequence of tokens they generate with probability 1, even if one knows all of their parameters $\theta$ (Expect of course if they are deterministic autoregressive models).  This means that $\mathbb H(H_T^{(M)}|\theta)$, e.g. the hardness of predicting the sequence even if the autoregressive model is known, has a value above 0 and might grow to infinity with T or M. The Authors named this error &ldquo;the irreducible error&rdquo;. As we are interessted in how hard it is to estimate not the series of tokens itself, but their distribution, the error $\mathcal L_{M,T} = \mathbb L_{M,T} - \dfrac{\mathbb H(H_T^{(M)}|\theta)}{MT}$ will be more insightfull in our exploration.
They call this error &ldquo;estimation error&rdquo;.</p>
<p>In the rest of this section we will present derived expressions for $\mathcal L_{M,T}$, that provide insights in how easy or hard it is to estimate model parameters, if the data was generated as discussed. Then we derive from this result an expression of the in-context error $\mathbb L_\tau := \frac{1}{\tau} \sum_{t=0}^{\tau-1} \mathbb E \ln \mathbb P(X_{t+1}^{(M+1)}| H_t^{(M+1)})$, where $\tau$ is the length of the in-context document.</p>
<p>Firstly we discuss two information theoretic results of $\mathcal L_{M,T}$.</p>
<p>$\mathcal L_{M,T} = \dfrac{\mathbb I(H_T^{(M)};\theta)}{MT}$</p>
<p>Proof:</p>
<p>We know $\mathbb H(X) = \mathbb H(X|Y) + \mathbb I(X;Y)$, therfore it suffices to show that $\mathbb L_{M,T} \cdot MT = \mathbb H(H_T^{(M)})$. This is true since:</p>
<p>$\sum_{m=1}^{M} \sum_{t=0}^{T-1} \mathbb E[ - \ln \mathbb P[X_{t+1}^{(m)}|H_t^{(m)}]] = \mathbb E[-\ln \prod_{m=1}^{M} \prod_{t=0}^{T-1} \mathbb P[X_{t+1}^{(m)}|H_t^{(m)}]] \overset{a)}{=} \mathbb E[-\ln  \mathbb P[H_T^{(M)}]]= \mathbb H(H_T^{(M)})$</p>
<p>a) follows from the chain rule of probability.</p>
<p>QED</p>
<p>Be  aware I often do mistakes, when proofing something.
I presented my own version of the proof of this equation as it contains the intermediate result $\mathbb L_{M,T}  = \dfrac{\mathbb H(H_T^{(M)})}{MT}$. Thus we can see $\mathbb L_{M,T}$ as the average entropy per token.</p>
<p>This equation means roughly speaking, that the estimation error consits of these parts in $\theta$, that are conveyed to $H_T^{(M)}$. For example as we often model $\theta$ as a continous random variable and $H_T^{(M)}$ as a discrete random variable, $H_T^{(M)}$ can not contain all information in $\theta$. (&lt;- be more clear)</p>
<p>As in previous section, we have worked out a way to separate $\theta = \theta_1, &hellip;\theta_m$ into two independent random variables, namely $\theta|\psi$ and $\psi$, we continue by expressing $\mathcal L_{M,T}$ with these two random variables.</p>
<p>$\mathcal L_{M,T} =
\underbrace{\dfrac{\mathbb I(H_T^{(M)};\psi)}{MT}}<em>\text{meta
estimation error} +
\underbrace{\dfrac{\mathbb I(D_m;\theta_m|\psi)}{T}}</em>\text{intra document estimation error}$</p>
<p>To proof this equation it suffices to show</p>
<ul>
<li>A) $\mathbb I(H_T^{(M)};\theta) = \mathbb I(H_T^{(M)};\psi) + \mathbb I(H_T^{(M)};\theta|\psi) $</li>
<li>B) $\mathbb I(H_T^{(M)};\theta|\psi) = M \cdot \mathbb I(D_m;\theta_m|\psi)$</li>
</ul>
<p>We defined earlier $D_m \bot \psi | \theta_m$, which means $ H_T^{(M)} \bot \psi | \theta$ (&lt;- be more formal?). Therefore $\mathbb I(H_T^{(M)};\theta) = \mathbb I(H_T^{(M)};(\theta, \psi))$. Then A) follows from the chain rule of mutual information.</p>
<p>B) follows from $\mathbb I(H_T^{(M)};\theta|\psi) \overset{a)}{=} \sum_{m=1}^M  \mathbb I(D_m;\theta_m|\psi) \overset{b)}{=} M\cdot \mathbb I(D_m;\theta_m|\psi) $.</p>
<p>Equation a) holds because the pairs $(D_1, \theta_1)|\psi, &hellip;, (D_M, \theta_M)|\psi$ are independent and mutual information is additive for independent variables.(<a href="http://www.scholarpedia.org/article/Mutual_information">http://www.scholarpedia.org/article/Mutual_information</a>)<br>
As $ D_1,&hellip;,D_M | \psi$ are identically distributed and $\theta_1, &hellip;, \theta_M | \psi$ are identically distributed, for any $a,b \in {1,&hellip;,M}$, $I(D_a;\theta_a|\psi) = I(D_b;\theta_b|\psi)$. Therefore b) is true.</p>
<p>(&lt;- proof not peer reviewed)
QED</p>
<p>The authors seperate the term into two parts, the meta estimation error and the intra document estimation error. The meta estimation error describes the error, of learning information shared shared by all documents. The intra document estimation error is the error of learning the parameters of learning individual documents after having learned the shared information $\psi$. Lets say we have arbitrarily many training samples $A$ for our optimal bayesian estimator in which $D_m$ does not occur. Due to them being arbitrarily many, let&rsquo;s suppose $\psi$ has been well enough discovered, such that $\mathbb I(D_m;\psi | A)$ is about 0. Then the error of estimating $D_m$ is about the intra-document error. This means, that even of we perfectly train our model, there will be some error bigger than zero related to the estimation of the probability that generates the data? Or will it realy be bigger than zero? More on this cliffhanger later (&lt;- TODO!)</p>
<h5 id="results-from-assumptions-of-bayesian-prior">Results from assumptions of bayesian prior<a hidden class="anchor" aria-hidden="true" href="#results-from-assumptions-of-bayesian-prior">#</a></h5>
<h3 id="discussion-assumptions">Discusion of their Assumptions<a hidden class="anchor" aria-hidden="true" href="#discussion-assumptions">#</a></h3>
<h4 id="when-can-we-make-assumptions-of-the-the-familie-of-ams">When can we make assumptions of the the familie of AMs<a hidden class="anchor" aria-hidden="true" href="#when-can-we-make-assumptions-of-the-the-familie-of-ams">#</a></h4>
<p>Lets suppose following scenario: we have a sequence of random tokens $X_1, &hellip;, X_T$ and know that this sequence is autoregressive with finite horizon T-d, which means $\mathbb P(X_{t+1} | X_{t-T+d}, &hellip;, X_{t-1}) = \mathbb P(X_{t+1}|H_t, X_{t+2}, &hellip;X_{T})$.
Then, the distribution of $H_T$ can be charachterized by the function $f(H_t) = \mathbb P(X_{t+1} | H_t)$. Thus there is a trivial bijection from the set ${ \Sigma^{T-d} \to \mathcal P_\Sigma }$ to the Autoregressive distributions over the alphabet $\Sigma$ and length $T$ and horizon $T-d$. (&lt;- warning you have to integrate the non character sign to sigma and that can only be place to the right position (change $\Sigma^T$)).</p>
<p>Lets suppose we are reely lucky and  find a parmatrization of all autoregressive distributions of horizon T-d by finding an injektive function $A :\mathbb J_\sigma^n \to {\Sigma^{T-d} \to \mathcal P_\Sigma }$, where $\mathbb J_\sigma ^n := {||x||_2 = \sigma, \mathbb{1} ^T x=0 | x \in \mathbb R^n}$.</p>
<p>(</p>
<p>Let now $\Theta \sim \mathcal N(0,I_n\sigma)$. Then $A(\Theta)$ is a random random distribution which itself is a random distribution. This means $A(\Theta) \in {\Sigma^T \to \mathcal P_\Sigma }$ (Note $X \sim \mathcal N(0,1) \to x \notin \mathbb R$)</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>If A exists, and we  insert random vector into A, then that random variable is element of As image</p>
<!-- raw HTML omitted -->
<p>To recapulate, we assumed/showed evidence, that there can exist a pair $A_t,\theta$ that can generate any upper bounded horizon distribution, when $\theta$ is empirical gaussian and $A_t$ is a parametrization function for transformers. Lets suppose we wanted to use that knowledge to find an upper bound for the error of the optimal bayeisan optimizer e.g.  an upper bound of the mutual information H_t Theta. Can we do that by using the random random distribution $\Theta \sim \mathcal N(0,\sigma)$, as that way $\Theta$ is the probability distribution with maximal differential entropy?</p>
<!-- raw HTML omitted -->
<p>The problem is, that there exists $\theta \in \mathbb J^n$, s.t. $A(\theta) = A(\Theta)$.</p>
<p>The problem is, that this assumes, that $A$ is the only function (it is actually class of function) that can do that (explain what). Why
suppose B (b entagles and makes dependencies)</p>
<p>)
!!!!!!
But $A(\theta)$ only has horizon of $K&lt;T$ and $A(\Theta)$ has infinite horizon (if A is paramatrization of transformers) and thus models and thus A can only exist for AMs with horizin at least T or with AMs that do not increase the horizon.</p>
<p>This means only a bayesian estimator with horizon T can detect $\Theta$??</p>
<p>conclusion from A: for each prior distribution of Theta there is a constant theta that creates a prediction error of 0 but the same distribution of X_t</p>
<h4 id="can-a-transformer-learn-a-random-transforer-as-the-obe-does">Can a Transformer learn a random transforer as the OBE does<a hidden class="anchor" aria-hidden="true" href="#can-a-transformer-learn-a-random-transforer-as-the-obe-does">#</a></h4>
<p>No, the AM represented by a random transformer has an event horizon of infinity.(&lt;- TODO proof. youse math snippes from previous section&gt;) Transformers only have a a</p>
<h4 id="a-sparce-mixture-of-transformers-has-an-infinite-horizon">A sparce Mixture of Transformers has an infinite horizon<a hidden class="anchor" aria-hidden="true" href="#a-sparce-mixture-of-transformers-has-an-infinite-horizon">#</a></h4>
<p>Suppose bernoulli distributed $\theta$ describing am with horizon of one. then $\theta$ together with am would create series with infinite horizon</p>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>In this blog post several applications of Information Theory in Deep Learning and LLMs where presented.</p>
<h2 id="take-home-messages">Take home messages<a hidden class="anchor" aria-hidden="true" href="#take-home-messages">#</a></h2>
<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>


  










<section class="hugo-cite-bibliography">
  <dl>
    

      <div id="jeon2024information">
        <dt>
          Jeon,&#32;
          Lee,&#32;
          Lei&#32;&amp;&#32;Van Roy

          
          (2024)</dt>

        <dd>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jeon</span>,&#32;
    <meta itemprop="givenName" content="Hong Jun" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lee</span>,&#32;
    <meta itemprop="givenName" content="Jason D" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Lei</span>,&#32;
    <meta itemprop="givenName" content="Qi" />
    Q.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Roy</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2024</span>).
  &#32;<span itemprop="name">An information-theoretic analysis of in-context learning</span>.<i>
    <span itemprop="about">arXiv preprint arXiv:2401.15530</span></i>.</span>




</dd>

      </div>

      <div id="jeon2022information">
        <dt>
          Jeon,&#32;
          Zhu&#32;&amp;&#32;Van Roy

          
          (2022)</dt>

        <dd>
          










<span itemscope
      itemtype="https://schema.org/Article"
      data-type="article"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Jeon</span>,&#32;
    <meta itemprop="givenName" content="Hong Jun" />
    H.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Zhu</span>,&#32;
    <meta itemprop="givenName" content="Yifan" />
    Y.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Van Roy</span>,&#32;
    <meta itemprop="givenName" content="Benjamin" />
    B.</span>
  &#32;
    (<span itemprop="datePublished">2022</span>).
  &#32;<span itemprop="name">An information-theoretic framework for supervised learning</span>.<i>
    <span itemprop="about">arXiv preprint arXiv:2203.00246</span></i>.</span>




</dd>

      </div>

      <div id="deletang2024language">
        <dt>
          Deletang,&#32;
          Ruoss,&#32;
          Duquenne,&#32;
          Catt,&#32;
          Genewein,&#32;
          Mattern,&#32;
          Grau-Moya,&#32;
          Wenliang,&#32;
          Aitchison,&#32;
          Orseau,&#32;
          Hutter&#32;&amp;&#32;Veness

          
          (2024)</dt>

        <dd>
          










<span itemscope
      itemtype="https://schema.org/CreativeWork"
      data-type="paper-conference"><span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Deletang</span>,&#32;
    <meta itemprop="givenName" content="Gregoire" />
    G.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Ruoss</span>,&#32;
    <meta itemprop="givenName" content="Anian" />
    A.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Duquenne</span>,&#32;
    <meta itemprop="givenName" content="Paul-Ambroise" />
    P.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Catt</span>,&#32;
    <meta itemprop="givenName" content="Elliot" />
    E.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Genewein</span>,&#32;
    <meta itemprop="givenName" content="Tim" />
    T.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Mattern</span>,&#32;
    <meta itemprop="givenName" content="Christopher" />
    C.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Grau-Moya</span>,&#32;
    <meta itemprop="givenName" content="Jordi" />
    J.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Wenliang</span>,&#32;
    <meta itemprop="givenName" content="Li Kevin" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Aitchison</span>,&#32;
    <meta itemprop="givenName" content="Matthew" />
    M.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Orseau</span>,&#32;
    <meta itemprop="givenName" content="Laurent" />
    L.</span>,&#32;
  <span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Hutter</span>,&#32;
    <meta itemprop="givenName" content="Marcus" />
    M.</span>&#32;&amp;&#32;<span itemprop="author" itemscope itemtype="https://schema.org/Person"><span itemprop="familyName">Veness</span>,&#32;
    <meta itemprop="givenName" content="Joel" />
    J.</span>
  &#32;
    (<span itemprop="datePublished">2024</span>).
  &#32;<span itemprop="name">
    <i>Language modeling is compression</i></span>.
  &#32;Retrieved from&#32;
  <a href="https://openreview.net/forum?id=jznbgiynus"
     itemprop="identifier"
     itemtype="https://schema.org/URL">https://openreview.net/forum?id=jznbgiynus</a></span>

</dd>

      </div>
  </dl>
</section>



<p><a href="https://perchance.org/emoji">https://perchance.org/emoji</a></p>
<p>Theorem:</p>
<p>Proof:
The sequence &ldquo;‚ö†Ô∏è üì• üòö üõ° üö¶ üëπ üåø&rdquo; in the beginning of the blogpost was generated at random.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://strammermax27.github.io/">Daniels Blog</a></span> ¬∑ 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
